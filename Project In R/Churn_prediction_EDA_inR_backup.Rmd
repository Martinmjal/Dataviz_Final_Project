---
title: "EDA_Proyecto_Final"
author: "Martin Alvarez, Estefany Villanueva"
date: "2023-11-14"
output: html_document
---

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
```


# Cargar los datos

```{r}
df <- read.csv('churn_prediction_features.csv')
```

Se eliminan unas columnas sin valor

```{r}
df <- subset(df, select = -c(KVI_gmv_percent, FORE_gmv_percent, LONG_gmv_percent, NO_CLASS_gmv_percent))
```

## Identificando variables categóricas y numéricas

Variables categóricas

Utilizando expresiones regulares, se buscan columnas cuyo nombre empiece por "sub_categoria_" & "warehouse_", posteriormente se agregan otras columnas que corresponden a variables categóricas

```{r}
categorical_cols <- names(df)[grepl("^sub_categoria_|^warehouse_", names(df))]
categorical_cols <- c(categorical_cols, 'customer_id', 'has_churned_before', 'is_churned')
```

Variables numéricas

Se toman las columnas del dataframe 'df' que no están en el vector de columnas categóricas

```{r}
numerical_cols <- setdiff(names(df), categorical_cols)
```

# Reducción de dimensionalidad

## variables categóricas

se verifica entonces la dimensión del dataframe de variables categóricas, eliminando la columna customer_id

```{r}
df_categoricals = subset(df, select = categorical_cols)
df_categoricals <- df_categoricals[, !(names(df_categoricals) %in% c("customer_id"))]

df_categoricals <- df_categoricals[-c(4168, 4713), ]

dim(df_categoricals)
```

se tienen 83 columnas categóricas, se procede a hacer pruebas de independencia de variables categóricas

### verificando supuestos de la prueba chi cuadrado

uno de los supuestos indica que debe haber almenos cinco ocurrencias de cada clase para cada variable categórica, por lo cuál procede a verificarse este supuesto

```{r}
# Inicializa un dataframe para almacenar los resultados
resultados <- data.frame(column_name = character(), negative_class = integer(), positive_class = integer())

# Calcula los conteos para cada columna
for (column_name in names(df_categoricals)) {
  positive_count <- sum(df_categoricals[[column_name]] == 1)
  negative_count <- sum(df_categoricals[[column_name]] == 0)
  
  # Añade los resultados al dataframe
  resultados <- rbind(resultados, data.frame(column_name, negative_class = negative_count, positive_class = positive_count))
}

library(knitr)
kable(head(resultados), caption = "Conteo de classes por variable")
```

categorías con menos de 5 registros en la clase negativa:

```{r}
resultados %>% filter(negative_class < 5)
```

categorías con menos de 5 registros en la clase positiva:

```{r}
resultados %>% filter(positive_class < 5)
```

por lo cuál proceden a excluírse estas categorías de la prueba

```{r}
df_categoricals <- df_categoricals[, !(names(df_categoricals) %in% c("sub_categoria_Detergentes.y.jabones"))]
```

### aplicando prueba chi cuadrado

dado que se tienen 83 columnas categóricas, se procede a hacer pruebas chi cuadrado entre todas las variables versus warehouse_Bogota (escogida aleatoriamente entre todas las variables) para posteriormente empezar a descartar.

```{r, warning=FALSE}
library(dplyr)

p_values <- numeric(length = ncol(df_categoricals) - 1)
names(p_values) <- setdiff(colnames(df_categoricals), "warehouse_Bogota")

# Realizar las pruebas de chi-cuadrado
for (col in names(p_values)) {
  # Crear la tabla de contingencia para cada columna con 'warehouse_Bogota'
  contingency_table <- table(df_categoricals$warehouse_Bogota, df_categoricals[[col]])
  
  # Realizar la prueba chi-cuadrado y almacenar el valor p
  test_result <- chisq.test(contingency_table)
  p_values[col] <- test_result$p.value
}

# Ahora, filtramos los nombres de las columnas con un valor p menor a 0.05
significant_columns <- names(p_values)[p_values > 0.05]
significant_columns <- significant_columns[!is.na(significant_columns)]
significant_columns <- c(significant_columns, "warehouse_Bogota")

significant_columns

df_independent_variables <- subset(df_categoricals, select = significant_columns)
```

por lo cuál, todas las que quedan son independientes a warehouse_Bogota, se procede a tomar otra columna aleatoria para verificar su independencia con todas las otras y seguir eliminando.

se toma la variable ‘sub_categoria_Ambientadores’, se eliminan las que son dependientes a esta y se repite el proceso hasta que todas las variables categóricas restantes, sean independientes

```{r, warning=FALSE}
p_values <- numeric(length = ncol(df_independent_variables) - 1)
names(p_values) <- setdiff(colnames(df_independent_variables), "sub_categoria_Ambientadores")

# Realizar las pruebas de chi-cuadrado
for (col in names(p_values)) {
  # Crear la tabla de contingencia para cada columna con 'sub_categoria_Ambientadores'
  contingency_table <- table(df_independent_variables$sub_categoria_Ambientadores, df_independent_variables[[col]])
  
  # Realizar la prueba chi-cuadrado y almacenar el valor p
  test_result <- chisq.test(contingency_table)
  p_values[col] <- test_result$p.value
}

# Ahora, filtramos los nombres de las columnas con un valor p menor a 0.05
significant_columns <- names(p_values)[p_values > 0.05]
significant_columns <- significant_columns[!is.na(significant_columns)]
significant_columns <- c(significant_columns, "sub_categoria_Ambientadores")

significant_columns

df_independent_variables <- subset(df_independent_variables, select = significant_columns)
```

ahora se repite con la sub categoria Complementos y vitaminas

```{r, warning=FALSE}
p_values <- numeric(length = ncol(df_independent_variables) - 1)
names(p_values) <- setdiff(colnames(df_independent_variables), "sub_categoria_Complementos.y.vitaminas")

# Realizar las pruebas de chi-cuadrado
for (col in names(p_values)) {
  # Crear la tabla de contingencia para cada columna con 'sub_categoria_Complementos.y.vitaminas'
  contingency_table <- table(df_independent_variables$sub_categoria_Complementos.y.vitaminas, df_independent_variables[[col]])
  
  # Realizar la prueba chi-cuadrado y almacenar el valor p
  test_result <- chisq.test(contingency_table)
  p_values[col] <- test_result$p.value
}

# Ahora, filtramos los nombres de las columnas con un valor p menor a 0.05
significant_columns <- names(p_values)[p_values > 0.05]
significant_columns <- significant_columns[!is.na(significant_columns)]
significant_columns <- c(significant_columns, "sub_categoria_Complementos.y.vitaminas")

significant_columns

df_independent_variables <- subset(df_independent_variables, select = significant_columns)
```

con lo cuál se tienen tres variables categóricas independientes para el modelo

## variables numéricas

examinando correlación

```{r, fig.width=12, fig.height=10}
library(reshape2)

# Asumiendo que 'numerical_cols' es un vector con los nombres de tus columnas numéricas
cor_matrix <- cor(df[numerical_cols], use = "complete.obs")

# Transforma la matriz de correlación para la visualización
cor_melted <- melt(cor_matrix)

# Configura el tamaño de la fuente para los labels (ajusta según sea necesario)
font_size <- 6

ggplot(data = cor_melted, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1, 1), space = "Lab", 
                       name="Correlation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = font_size),
        axis.text.y = element_text(size = font_size)) +
  coord_fixed() +
  labs(x = '', y = '') +
  geom_text(aes(label = sprintf("%.2f", value)), size = 3, check_overlap = TRUE)
```

se evidencian variables con correlaciones muy altas, pero estas se proceden a eliminar con el VIF (Variance Inflation Factor)

## valores nulos

se verifica antes de calcular el VIF, que no hayan valores nulos.

```{r}
columns_for_reduction = c(numerical_cols, significant_columns, 'is_churned')

df_reduction = subset(df, select = columns_for_reduction)

dim(df_reduction)
```

```{r}
# Calcula el porcentaje de valores nulos por columna
null_percent <- sapply(df_reduction, function(x) mean(is.na(x))) * 100

# Convierte a dataframe para la visualización
null_df <- data.frame(Column = names(null_percent), Null_Percentage = null_percent)

# Crea el gráfico de barras
ggplot(null_df, aes(x = Column, y = Null_Percentage)) +
  geom_bar(stat = "identity", fill = "blue") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(x = "Column Name", y = "Percentage of Null Values", 
       title = "Percentage of Null Values in Each Column")
```

En este caso se eliminan columnas con un 40% o más de valores nulos, y al resto se le imputa la mediana

```{r}
# 1. Eliminar columnas con 40% o más de valores nulos
porcentaje_nulos <- sapply(df_reduction, function(x) mean(is.na(x))) * 100
df_filtrado <- df_reduction[, porcentaje_nulos < 40]

# 2. Imputar la mediana en las columnas restantes
df_imputado <- df_filtrado
for (nombre_columna in names(df_imputado)) {
  # Calcula la mediana de la columna, excluyendo NA
  mediana <- median(df_imputado[[nombre_columna]], na.rm = TRUE)
  # Reemplaza NA con la mediana en la columna
  df_imputado[[nombre_columna]][is.na(df_imputado[[nombre_columna]])] <- mediana
}

dim(df_imputado)
```

con lo cual restan 25 columnas

### Eliminando multicolinealidad con Variance Inflation Factor (VIF)

Recordemos que:

- Un VIF ≥ 5 indica alta multicolinealidad entre la correspondiente variable independiente y las demás variables.

- Recomendación: Eliminar una columna a la vez. Aquella con el máximo VIF ≥ 5. Luego, para el nuevo dataframe, calcular nuevamente VIF e identificar nuevas columnas con VIF ≥ 5 máximo, y así sucesivamente hasta obtener solo valores de VIF < 5.

- Según corresponda, variables categóricas deben previamente codificarse usando por ejemplo OneHotEncoder().

```{r, message=FALSE, warning=FALSE}
library(car)

modelo <- lm(is_churned ~ ., data = df_imputado)

# Calcular VIF
vif_valores <- vif(modelo)

# Crear un dataframe para mostrar los nombres de las variables y sus VIFs
vif_df <- data.frame(VIF = vif_valores)

# Imprimir el dataframe
kable(vif_df, caption = "VIF values")
```

se eliminan las columnas con un VIF mayor que 5, eliminando la de mayor VIF en cada iteración

```{r}
# Definir el umbral para el VIF
vif_threshold <- 5

# Crear una copia del dataframe original para no modificarlo directamente
df_reduction_copy <- df_reduction

# Bucle para calcular VIF y eliminar la variable con el mayor VIF
while(TRUE) {
  # Ajustar un modelo de regresión lineal usando 'is_churned' como la variable de respuesta
  formula <- as.formula(paste("is_churned ~", paste(setdiff(names(df_reduction_copy), "is_churned"), collapse="+")))
  modelo <- lm(formula, data=df_reduction_copy)
  
  # Calcular VIF
  vif_valores <- vif(modelo)
  
  # Obtener el máximo VIF y el nombre de la variable correspondiente
  max_vif <- max(vif_valores)
  if (max_vif < vif_threshold) {
    break
  }
  variable_max_vif <- names(vif_valores)[which.max(vif_valores)]
  
  # Imprimir la variable que se está eliminando y su VIF
  cat(sprintf("Dropping '%s' with VIF: %f\n", variable_max_vif, max_vif))
  
  # Eliminar la variable con el VIF más alto
  df_reduction_copy <- df_reduction_copy[, !(names(df_reduction_copy) %in% variable_max_vif)]
}
```

y ahora se imprime el dataframe resultante con sus respectivos VIF

```{r, message=FALSE, warning=FALSE}
modelo <- lm(is_churned ~ ., data = df_reduction_copy)

# Calcular VIF
vif_valores <- vif(modelo)

# Crear un dataframe para mostrar los nombres de las variables y sus VIFs
vif_df <- data.frame(VIF = vif_valores)

# Imprimir el dataframe
kable(vif_df, caption = "VIF values")
```

por lo cual el dataframe utilizado para entrenar el modelo será el siguiente

```{r}
df_final <- df_reduction_copy

library(DT)
datatable(tail(df_final, 10), options = list(scrollX = TRUE))
```

# Descripción variable objetivo

```{r, message=FALSE, warning=FALSE}
# Reemplazar 0 y 1 en la columna 'is_churned' con etiquetas
df_reduction_copy$is_churned <- factor(df_reduction_copy$is_churned, levels = c(0, 1), labels = c("not churned", "churned"))

# Crear el gráfico de conteo
ggplot(data = df_reduction_copy, aes(x = is_churned)) +
  geom_bar(fill = "blue") +
  labs(title = "Count of churned and non churned customers",
       x = "",
       y = "Count")
```

# Descripción variables numericas vs is_churned

```{r, message=FALSE, warning=FALSE}
numerical_cols <- setdiff(names(df_reduction_copy), c('warehouse_Bogota', 'sub_categoria_Ambientadores', 'sub_categoria_Complementos.y.vitaminas', 'is_churned'))

# Crear un boxplot para cada columna numérica
for (col in numerical_cols) {
  p <- ggplot(df_reduction_copy, aes_string(x = "is_churned", y = col)) +
    geom_boxplot() +  # Elimina outliers
    coord_flip() +  # Hace el boxplot horizontal
    labs(title = paste("Boxplot of", col, "by is_churned"),
         y = col,
         x = "is_churned")
  print(p)
}
```

# variables categoricas vs is_churned

```{r, message=FALSE, warning=FALSE}

df_categoricals_final <- df[, c(significant_columns, 'is_churned')]

df_categoricals_final$is_churned <- factor(df_categoricals_final$is_churned, levels = c(0, 1), labels = c("not churned", "churned"))

# Crear un gráfico de barras apiladas para cada variable categórica
for (col in significant_columns) {
  # Calcular los porcentajes
  df_percent <- df_categoricals_final %>%
    group_by_at(col) %>%
    count(is_churned) %>%
    group_by_at(col) %>%
    mutate(perc = n / sum(n) * 100)

  # Crear el gráfico
  p <- ggplot(df_percent, aes_string(x = col, y = "perc", fill = "is_churned")) +
    geom_bar(stat = "identity", position = "fill") +
    labs(title = paste("Porcentaje de is_churned por", col),
         x = col,
         y = "Porcentaje (%)") +
    scale_y_continuous(labels = scales::percent)

  print(p)
}
```